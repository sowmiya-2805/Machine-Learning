{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                 DATA PREPOCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEATHER DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the datafiles of unwanted years from weather folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_path = #path to the weather folder\n",
    "os.chdir(weather_path)\n",
    "airports = os.listdir()\n",
    "for i in range(len(airports)):\n",
    "    path = weather_path + airports[i]\n",
    "    for fname in os.listdir(path):\n",
    "        if fname.startswith(\"2013\"):\n",
    "            os.remove(os.path.join(path, fname))\n",
    "            \n",
    "    for fname in os.listdir(path):\n",
    "        if fname.startswith(\"2014\"):\n",
    "            os.remove(os.path.join(path, fname))\n",
    "            \n",
    "    for fname in os.listdir(path):\n",
    "        if fname.startswith(\"2015\"):\n",
    "            os.remove(os.path.join(path, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the json files to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(weather_path)\n",
    "for i in range(len(airports)):\n",
    "    path1 = weather_path+airports[i]\n",
    "    os.chdir(path1)\n",
    "    reports = os.listdir()\n",
    "    for j in range(len(reports)):\n",
    "        if reports[j].endswith(\".json\"):\n",
    "            path = path1 + '/' + reports[j]\n",
    "            with open(path, 'r') as json_file:\n",
    "                json_data  = json.load(json_file)\n",
    "            weather_record = json_data['data']['weather']\n",
    "            csv_data = open(os.path.splitext(path)[0]+'.csv', 'w')\n",
    "            csv_writer = csv.writer(csv_data)\n",
    "            count = 0\n",
    "            for i in weather_record:\n",
    "                if count == 0:\n",
    "                    header = i.keys()\n",
    "                    csv_writer.writerow(header)\n",
    "                    count += 1\n",
    "                csv_writer.writerow(i.values())\n",
    "    csv_data.close()\n",
    "\n",
    "#Seggregating the csv files\n",
    "os.chdir(weather_path)\n",
    "for i in range(len(airports)):\n",
    "    path1 = weather_path+airports[i]\n",
    "    os.mkdir(path1 + '/CSV FILES')\n",
    "\n",
    "os.chdir(weather_path)\n",
    "for i in range(len(airports)):\n",
    "    path1 = weather_path+airports[i]\n",
    "    os.chdir(path1)\n",
    "    files = os.listdir()\n",
    "    for i in range(len(files)):\n",
    "        src = path1 + '/' + files[i]\n",
    "        dest = path1 + '/CSV FILES'\n",
    "        if files[i].endswith('.csv'):\n",
    "            shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the weather data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 10)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(weather_path+'ATL/CSV FILES/')\n",
    "sample_weather = pd.read_csv('2016-1.csv')\n",
    "print(sample_weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mintempC', 'maxtempF', 'sunHour', 'mintempF', 'maxtempC', 'hourly',\n",
      "       'totalSnow_cm', 'date', 'astronomy', 'uvIndex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sample_weather.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefining weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(weather_path)\n",
    "for i in range(len(airports)):\n",
    "    path1 = weather_path+airports[i]+'/CSV FILES'\n",
    "    os.chdir(path1)\n",
    "    files = os.listdir()\n",
    "    for j in range(len(files)):\n",
    "        df1 = pd.read_csv(path1 + '/' + files[j])\n",
    "        \n",
    "        df1 = df1.drop(['mintempC', 'maxtempF', 'sunHour', 'mintempF', 'maxtempC', 'totalSnow_cm', 'astronomy', 'uvIndex'], axis = 1)\n",
    "        \n",
    "        for k in range(len(df1['hourly'])):\n",
    "            df1['hourly'][k] = json.loads(df1['hourly'][k].replace(\"'\", '\"'))\n",
    "            \n",
    "        unwanted = ['FeelsLikeF', 'FeelsLikeC', 'DewPointC', 'winddir16Point', 'windspeedMiles', 'HeatIndexF', 'HeatIndexC', 'weatherIconUrl', 'weatherDesc', 'tempC', 'WindChillC']\n",
    "        for l in range(len(df1['hourly'])):\n",
    "            for m in range(len(df1['hourly'][l])):\n",
    "                #print(str2[i])\n",
    "                for key in unwanted:\n",
    "                    del df1['hourly'][l][m][key]\n",
    "        \n",
    "        df1 = df1.rename(columns = {'Unnamed: 0' : 'Airport'})\n",
    "        \n",
    "        df1['Airport'] = airports[i]\n",
    "        \n",
    "        df1.to_csv(path1 + '/' + files[j])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'windspeedKmph': '17',\n",
       " 'DewPointF': '68',\n",
       " 'cloudcover': '14',\n",
       " 'precipMM': '0.0',\n",
       " 'WindGustMiles': '17',\n",
       " 'pressure': '1022',\n",
       " 'WindGustKmph': '27',\n",
       " 'visibility': '10',\n",
       " 'weatherCode': '116',\n",
       " 'tempF': '74',\n",
       " 'WindChillF': '74',\n",
       " 'winddirDegree': '94',\n",
       " 'humidity': '82',\n",
       " 'time': '0'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['hourly'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowmiya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for m in range(len(airports)):\n",
    "    path1 = weather_path+airports[m]+'/CSV FILES'\n",
    "    os.chdir(path1)\n",
    "    files = os.listdir()\n",
    "    for n in range(len(files)):\n",
    "        data2 = pd.read_csv(files[n])\n",
    "        for x in range(len(data2['hourly'])):\n",
    "            data2['hourly'][x] = json.loads(data2['hourly'][x].replace(\"'\", '\"'))\n",
    "        columns = data2.columns\n",
    "        for v in range(len(columns)):\n",
    "            if(columns[v] == \"Unnamed: 0\"):\n",
    "                data2 = data2.drop(columns[v], axis = 1)\n",
    "        \n",
    "        data_new = pd.DataFrame(columns=['Airport', 'Date', 'Time', 'windspeedKmph', 'DewPointF', 'cloudcover', 'precipMM', 'pressure', 'WindGustKmph', 'visibility', 'weatherCode', 'tempF', 'WindChillF', 'winddirDegree', 'humidity'])\n",
    "\n",
    "        for x in range(len(data2)):\n",
    "            for y in range(len(data2['hourly'][x])):\n",
    "                data_new = data_new.append({'Airport': data2['Airport'][x], 'Date': data2['date'][x], 'Time':data2['hourly'][x][y]['time'], 'windspeedKmph':data2['hourly'][x][y]['windspeedKmph'], 'DewPointF': data2['hourly'][x][y]['DewPointF'], 'cloudcover': data2['hourly'][x][y]['cloudcover'], 'precipMM': data2['hourly'][x][y]['precipMM'], 'pressure': data2['hourly'][x][y]['pressure'], 'WindGustKmph': data2['hourly'][x][y]['WindGustKmph'], 'visibility': data2['hourly'][x][y]['visibility'], 'weatherCode': data2['hourly'][x][y]['weatherCode'], 'tempF': data2['hourly'][x][y]['tempF'], 'WindChillF': data2['hourly'][x][y]['WindChillF'], 'winddirDegree': data2['hourly'][x][y]['winddirDegree'], 'humidity': data2['hourly'][x][y]['humidity']}, ignore_index=True)\n",
    "        \n",
    "        data_new.to_csv(files[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Airport', 'Date', 'Time', 'windspeedKmph', 'DewPointF', 'cloudcover',\n",
       "       'precipMM', 'pressure', 'WindGustKmph', 'visibility', 'weatherCode',\n",
       "       'tempF', 'WindChillF', 'winddirDegree', 'humidity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(weather_path+'ATL/CSV FILES/')\n",
    "df = pd.read_csv('2016-1.csv')\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLIGHT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving the flight csv files directly into flight_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_data_2016 = []\n",
    "flight_data_2017 = []\n",
    "flight_path = #path to the folder containing the flight details\n",
    "os.chdir(flight_path)\n",
    "for fname in os.listdir(flight_path):\n",
    "        if fname.endswith(\".DS_Store\"):\n",
    "            os.remove(os.path.join(flight_path, fname))\n",
    "            \n",
    "year_2016_path = #2016 subfolder in flight folder\n",
    "year_2017_path = #2017 subfolder in flight folder\n",
    "\n",
    "months_2016 = os.listdir(year_2016_path)\n",
    "for i in range(len(months_2016)):\n",
    "    files_2016 = year_2016_path + months_2016[i]\n",
    "    list1 = os.listdir(files_2016)\n",
    "    for j in list1:\n",
    "        if j.endswith(\".csv\"):\n",
    "            flight_data_2016.append(j)            \n",
    "months_2017 = os.listdir(year_2017_path)\n",
    "for k in range(len(months_2017)):\n",
    "    files_2017 = year_2017_path + months_2017[k]\n",
    "    list2 = os.listdir(files_2017)\n",
    "    for l in list2:\n",
    "        if l.endswith(\".csv\"):\n",
    "            flight_data_2017.append(l)\n",
    "\n",
    "for x in range(len(flight_data_2016)):\n",
    "    src = year_2016_path + months_2016[x] +'/' + flight_data_2016[x]\n",
    "    dest = flight_path\n",
    "    shutil.move(src, dest)\n",
    "    \n",
    "for y in range(len(flight_data_2017)):\n",
    "    src = year_2017_path + months_2017[y] +'/' + flight_data_2017[y]\n",
    "    dest = flight_path\n",
    "    shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefining flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowmiya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/sowmiya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/sowmiya/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/sowmiya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/sowmiya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "os.chdir(flight_path)\n",
    "\n",
    "#creating a list of flight csv files\n",
    "for data in os.listdir(flight_path):\n",
    "        if data.endswith(\".DS_Store\"):\n",
    "            os.remove(os.path.join(flight_path, data))\n",
    "flight_data = os.listdir(flight_path)\n",
    "\n",
    "#unnecassary columns to drop\n",
    "drop = ['DayOfWeek', 'UniqueCarrier', 'AirlineID', 'Carrier', 'TailNum', 'FlightNum', 'OriginAirportSeqID', 'OriginCityMarketID', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac', 'DestAirportSeqID', 'DestCityMarketID', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'DepDelay', 'DepartureDelayGroups', 'DepTimeBlk', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'LateAircraftDelay', 'TaxiIn', 'ArrDelay', 'ArrivalDelayGroups', 'ArrTimeBlk', 'Cancelled', 'CancellationCode', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1Airport', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div1TailNum', 'Div2Airport', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div2TailNum', 'Div3Airport', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div3TailNum', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum', 'Unnamed: 109']\n",
    "\n",
    "#since each of the csv file is huge, we read the csv through dask and then drop the columns in drop[] list\n",
    "for i in range(len(flight_data)):\n",
    "    solved_data = dd.read_csv(flight_data[i], dtype = {'Div2Airport': 'object', 'Div2TailNum':'object', 'ArrTime': 'float64','CancellationCode': 'object','DepTime': 'float64','DepartureDelayGroups': 'float64','WheelsOff': 'float64','WheelsOn': 'float64', 'Div1TailNum': 'object', 'DivAirportLandings': 'float64', 'Div3Airport': 'object', 'Div1Airport': 'object', 'ArrivalDelayGroups': 'float64'})\n",
    "    solved_data = solved_data.compute()\n",
    "    for j in range(len(drop)):\n",
    "        solved_data = solved_data.drop(drop[j], axis = 1)\n",
    "    solved_data.to_csv(flight_data[i])\n",
    "\n",
    "#selecting only those rows that have station codes for which the weather data is provided(both origin and destination)\n",
    "for j in (flight_data):\n",
    "    d1 = pd.read_csv(j)\n",
    "    columns1 = d1.columns\n",
    "    for m in range(len(columns1)):\n",
    "        if(columns1[m] == \"Unnamed: 0\"):\n",
    "            d1 = d1.drop(columns1[m], axis = 1)\n",
    "            \n",
    "    d2 = d1[(d1['Origin'].isin(airports))]\n",
    "    d3 = d2[d2['Dest'].isin(airports)]\n",
    "    d3['CRSArrTime_round'] = \"\"\n",
    "    \n",
    "    #rounding off the CRSArrTime to merge it with the weather data of the Destination station\n",
    "    index = d3.index\n",
    "    def truncate(n):\n",
    "        return n%100\n",
    "    for y in index:\n",
    "        dec = truncate(d3['CRSArrTime'][y])\n",
    "        if(dec <= 30):\n",
    "            d3['CRSArrTime_round'][y] = int(d3['CRSArrTime'][y]/100) * 100\n",
    "        elif(dec > 30):\n",
    "            d3['CRSArrTime_round'][y] = (int(d3['CRSArrTime'][y]/100)+1) * 100\n",
    "        if(d3['CRSArrTime_round'][y] > 2300):\n",
    "            d3['CRSArrTime_round'][y] = 0\n",
    "    d3.to_csv(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Quarter', 'Month', 'DayofMonth', 'FlightDate',\n",
      "       'OriginAirportID', 'Origin', 'DestAirportID', 'Dest', 'CRSDepTime',\n",
      "       'DepTime', 'DepDelayMinutes', 'DepDel15', 'CRSArrTime', 'ArrTime',\n",
      "       'ArrDelayMinutes', 'ArrDel15', 'CarrierDelay', 'CRSArrTime_round'],\n",
      "      dtype='object')\n",
      "(75010, 19)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/Sowmiya/SF/MLProject/Sample/Flight Data/')\n",
    "df = pd.read_csv('On_Time_On_Time_Performance_2016_1.csv')\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "#df.head(2)\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINING THE FLIGHT AND WEATHER DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining all the flight data files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame(columns = ['Year', 'Quarter', 'Month', 'DayofMonth', 'FlightDate', 'OriginAirportID', 'Origin', 'DestAirportID', 'Dest', 'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'DepDel15', 'CRSArrTime', 'ArrTime', 'ArrDelayMinutes', 'ArrDel15', 'CRSArrTime_round','CarrierDelay'])\n",
    "for x in flight_data:\n",
    "    os.chdir(flight_path)\n",
    "    df = pd.read_csv(x)\n",
    "    \n",
    "    columns = df.columns\n",
    "    for m in range(len(columns)):\n",
    "        if(columns[m] == \"Unnamed: 0\"):\n",
    "            df = df.drop(columns[m], axis = 1)\n",
    "    \n",
    "    combined = pd.concat([combined, df])\n",
    "    \n",
    "    os.chdir(#path to the data folder)\n",
    "    combined.to_csv('flight.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining all weather data files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in airports:\n",
    "    airport_combined = pd.DataFrame(columns = ['Airport', 'Date', 'Time', 'windspeedKmph', 'DewPointF',\n",
    "       'cloudcover', 'precipMM', 'pressure', 'WindGustKmph', 'visibility',\n",
    "       'weatherCode', 'tempF', 'WindChillF', 'winddirDegree', 'humidity'])\n",
    "    os.chdir(weather_path + i + '/CSV FILES/')\n",
    "    files = os.listdir()\n",
    "    for j in range(len(files)):\n",
    "        os.chdir(weather_path + i + '/CSV FILES/')\n",
    "        df = pd.read_csv(files[j])\n",
    "        columns = df.columns\n",
    "        for m in range(len(columns)):\n",
    "            if(columns[m] == \"Unnamed: 0\"):\n",
    "                df = df.drop(columns[m], axis = 1)\n",
    "            \n",
    "        airport_combined = pd.concat([airport_combined, df])\n",
    "    \n",
    "        os.chdir(weather_path)\n",
    "        airport_combined.to_csv(i + '.csv')\n",
    "        \n",
    "        \n",
    "os.chdir(weather_path)\n",
    "stations = []\n",
    "for x in os.listdir():\n",
    "    if(x.endswith('.csv')):\n",
    "        stations.append(x)\n",
    "combined =  pd.DataFrame(columns = ['Airport', 'Date', 'Time', 'windspeedKmph', 'DewPointF',\n",
    "       'cloudcover', 'precipMM', 'pressure', 'WindGustKmph', 'visibility',\n",
    "       'weatherCode', 'tempF', 'WindChillF', 'winddirDegree', 'humidity'])\n",
    "for y in stations:\n",
    "    os.chdir(weather_path)\n",
    "    df1 = pd.read_csv(y)\n",
    "    \n",
    "    columns = df1.columns\n",
    "    for m in range(len(columns)):\n",
    "        if(columns[m] == \"Unnamed: 0\"):\n",
    "            df1 = df1.drop(columns[m], axis = 1)\n",
    "            \n",
    "    combined = pd.concat([combined, df1])\n",
    "    \n",
    "    os.chdir(#path to the data folder')\n",
    "    combined.to_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete merge of flight and weather data into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(#path to data folder)\n",
    "\n",
    "df1 = pd.read_csv('flight.csv')\n",
    "columns1 = df1.columns\n",
    "for m in range(len(columns1)):\n",
    "    if(columns1[m] == \"Unnamed: 0\"):\n",
    "        df1 = df1.drop(columns1[m], axis = 1)\n",
    "\n",
    "df2 = pd.read_csv('weather.csv')\n",
    "columns2 = df1.columns\n",
    "for m in range(len(columns2)):\n",
    "    if(columns2[m] == \"Unnamed: 0\"):\n",
    "        df1 = df1.drop(columns2[m], axis = 1)\n",
    "\n",
    "df3 = pd.merge(df1, df2, left_on = ['FlightDate', 'Dest', 'CRSArrTime_round'], right_on = ['Date', 'Airport', 'Time'])\n",
    "\n",
    "df3.to_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  REDEFINING THE FINAL MERGED DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>Origin</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>Dest</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>...</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>pressure</th>\n",
       "      <th>WindGustKmph</th>\n",
       "      <th>visibility</th>\n",
       "      <th>weatherCode</th>\n",
       "      <th>tempF</th>\n",
       "      <th>WindChillF</th>\n",
       "      <th>winddirDegree</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>12892</td>\n",
       "      <td>LAX</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>736</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>386</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>10397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>1350</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>386</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>1120</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>386</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877291</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>11057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>2345</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>192</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877292</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>10397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1019</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>219</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877293</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>13303</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2300</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>124</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877294</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>10397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2130</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1019</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>236</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877295</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>10397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2130</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1018</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877296 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year  Quarter  Month  DayofMonth  FlightDate  OriginAirportID Origin  \\\n",
       "0        2016        3      8          27  2016-08-27            11292    DEN   \n",
       "1        2016        3      8          27  2016-08-27            12892    LAX   \n",
       "2        2016        3      8          27  2016-08-27            12889    LAS   \n",
       "3        2016        3      8          27  2016-08-27            10397    ATL   \n",
       "4        2016        3      8          27  2016-08-27            11298    DFW   \n",
       "...       ...      ...    ...         ...         ...              ...    ...   \n",
       "1877291  2016        2      5          11  2016-05-11            11292    DEN   \n",
       "1877292  2016        2      5          11  2016-05-11            11292    DEN   \n",
       "1877293  2016        2      5          11  2016-05-11            12889    LAS   \n",
       "1877294  2016        2      5          12  2016-05-12            12889    LAS   \n",
       "1877295  2016        2      5          20  2016-05-20            12889    LAS   \n",
       "\n",
       "         DestAirportID Dest  CRSDepTime  ...  cloudcover  precipMM  pressure  \\\n",
       "0                12889  LAS         600  ...          47       0.0      1012   \n",
       "1                12889  LAS         620  ...          47       0.0      1012   \n",
       "2                13204  MCO         736  ...          60       0.7      1016   \n",
       "3                13204  MCO        1350  ...          60       0.7      1016   \n",
       "4                13204  MCO        1120  ...          60       0.7      1016   \n",
       "...                ...  ...         ...  ...         ...       ...       ...   \n",
       "1877291          11057  CLT        2345  ...           2       0.0      1018   \n",
       "1877292          10397  ATL        2359  ...           0       0.0      1019   \n",
       "1877293          13303  MIA        2300  ...           4       0.0      1020   \n",
       "1877294          10397  ATL        2130  ...           1       0.0      1019   \n",
       "1877295          10397  ATL        2130  ...         100       0.3      1018   \n",
       "\n",
       "         WindGustKmph  visibility  weatherCode  tempF  WindChillF  \\\n",
       "0                   8          10          113     78          77   \n",
       "1                   8          10          113     78          77   \n",
       "2                  23          10          386     84          85   \n",
       "3                  23          10          386     84          85   \n",
       "4                  23          10          386     84          85   \n",
       "...               ...         ...          ...    ...         ...   \n",
       "1877291            18          10          113     69          68   \n",
       "1877292            14          10          113     69          69   \n",
       "1877293            19          10          113     75          75   \n",
       "1877294             6          10          113     68          70   \n",
       "1877295            19           3          266     63          63   \n",
       "\n",
       "         winddirDegree  humidity  \n",
       "0                   30        49  \n",
       "1                   30        49  \n",
       "2                   84        53  \n",
       "3                   84        53  \n",
       "4                   84        53  \n",
       "...                ...       ...  \n",
       "1877291            192        75  \n",
       "1877292            219        84  \n",
       "1877293            124        82  \n",
       "1877294            236        71  \n",
       "1877295             77        88  \n",
       "\n",
       "[1877296 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(#path to data folder)\n",
    "x = pd.read_csv('data.csv')\n",
    "x = x.drop(\"Unnamed: 0\", axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for null values and if any occurs, dropping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                      0\n",
       "Quarter                   0\n",
       "Month                     0\n",
       "DayofMonth                0\n",
       "FlightDate                0\n",
       "OriginAirportID           0\n",
       "Origin                    0\n",
       "DestAirportID             0\n",
       "Dest                      0\n",
       "CRSDepTime                0\n",
       "DepTime               20980\n",
       "DepDelayMinutes       20987\n",
       "DepDel15              20987\n",
       "CRSArrTime                0\n",
       "ArrTime               22080\n",
       "ArrDelayMinutes       25860\n",
       "ArrDel15              25860\n",
       "CRSArrTime_round          0\n",
       "CarrierDelay        1489238\n",
       "Unnamed: 0.1              0\n",
       "Airport                   0\n",
       "Date                      0\n",
       "Time                      0\n",
       "windspeedKmph             0\n",
       "DewPointF                 0\n",
       "cloudcover                0\n",
       "precipMM                  0\n",
       "pressure                  0\n",
       "WindGustKmph              0\n",
       "visibility                0\n",
       "weatherCode               0\n",
       "tempF                     0\n",
       "WindChillF                0\n",
       "winddirDegree             0\n",
       "humidity                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                0\n",
       "Quarter             0\n",
       "Month               0\n",
       "DayofMonth          0\n",
       "FlightDate          0\n",
       "OriginAirportID     0\n",
       "Origin              0\n",
       "DestAirportID       0\n",
       "Dest                0\n",
       "CRSDepTime          0\n",
       "DepTime             0\n",
       "DepDelayMinutes     0\n",
       "DepDel15            0\n",
       "CRSArrTime          0\n",
       "ArrTime             0\n",
       "ArrDelayMinutes     0\n",
       "ArrDel15            0\n",
       "CRSArrTime_round    0\n",
       "CarrierDelay        0\n",
       "Unnamed: 0.1        0\n",
       "Airport             0\n",
       "Date                0\n",
       "Time                0\n",
       "windspeedKmph       0\n",
       "DewPointF           0\n",
       "cloudcover          0\n",
       "precipMM            0\n",
       "pressure            0\n",
       "WindGustKmph        0\n",
       "visibility          0\n",
       "weatherCode         0\n",
       "tempF               0\n",
       "WindChillF          0\n",
       "winddirDegree       0\n",
       "humidity            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unnecessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop(['Unnamed: 0.1', 'Airport', 'Date', 'Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877296, 31)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally writing the changes back to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
